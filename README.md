# ğŸ”§ Predictive Maintenance Failure Detection Project ğŸš€

## ğŸŒŸ Project Overview

This project focuses on **Predictive Maintenance** for industrial machinery using **Machine Learning** ğŸ§ . The goal is to **predict machine failures** (Target) and classify **failure types** to assist in **preventive maintenance planning**, reduce downtime â±ï¸, and save operational costs ğŸ’°.

The dataset contains machine operational metrics such as **temperature, torque, rotational speed, and tool wear**, along with failure indicators. This project demonstrates a **full ML pipeline** from data cleaning to model training and evaluation.

---

## ğŸ“Š Dataset Description

| Feature                   | Description                                          |
| ------------------------- | ---------------------------------------------------- |
| `UDI`                     | Unique identifier for each machine ğŸ†”                |
| `Product ID`              | Machine model identifier ğŸ­                          |
| `Type`                    | Machine type: `M` = Medium, `H` = High, `L` = Low âš™ï¸ |
| `Air temperature [K]`     | Ambient temperature during operation ğŸŒ¡ï¸              |
| `Process temperature [K]` | Process-specific temperature ğŸ› ï¸                      |
| `Rotational speed [rpm]`  | Machine speed in revolutions per minute ğŸ”„           |
| `Torque [Nm]`             | Torque applied to tools or shafts ğŸ‹ï¸                 |
| `Tool wear [min]`         | Cumulative tool wear â³                              |
| `Target`                  | Binary: 0 = No Failure, 1 = Failure âŒâœ…             |
| `Failure Type`            | Multi-label: `HDA, NF, OF, PF, RF, TWF` ğŸš¨           |

---

## ğŸ§¹ Data Preprocessing

### 1ï¸âƒ£ Handling Outliers

- Used **Interquartile Range (IQR)** method to detect and remove outliers ğŸ•µï¸â€â™‚ï¸.
- Outliers can bias model training, so we carefully cleaned the dataset.

### 2ï¸âƒ£ Feature Scaling

- Applied **RobustScaler** to reduce the influence of remaining outliers.
- For Neural Networks, applied **MinMaxScaler** to normalize values between 0ï¸âƒ£â€“1ï¸âƒ£.

### 3ï¸âƒ£ Encoding Categorical Features

- **Machine Type**: Ordinal encoding (`M=2, H=1, L=0`) ğŸ­ â†’ ğŸ”¢
- **Failure Type**: One-hot encoding (`HDA, NF, OF, PF, RF, TWF`) ğŸ§© â†’ avoids ordinal assumptions.

### 4ï¸âƒ£ Handling Imbalanced Classes

- Failure types are extremely imbalanced âš–ï¸ (e.g., `Random Failures` are very rare).
- Used **SMOTE** & **RandomOverSampler** to boost minority failure classes to **~800â€“1500 samples** without altering non-failure samples.
- Ensured **Target column remains consistent** with oversampled failure rows.

---

## ğŸ” Exploratory Data Analysis (EDA)

### 1ï¸âƒ£ Numerical Features

- Boxplots ğŸ“¦ & strip plots âœ¨ were created for numerical features against `Failure Type`.
- Checked skewness and applied **log transformation** to highly skewed features like `Rotational speed [rpm]`.

### 2ï¸âƒ£ Categorical Features

- Pie charts ğŸ¥§ and count plots ğŸ“ˆ show distribution of failures for each type.
- Correlation heatmaps ğŸ”¥ reveal relationships between failure types and operational metrics.

### 3ï¸âƒ£ Visualizations

- Tool wear distribution by **failure vs non-failure**.
- Feature comparison across **failure types** for deeper insights.

---

## ğŸ¤– Machine Learning Approach

### 1ï¸âƒ£ Problem Formulation

- **Target Prediction**: Binary classification (0 = No Failure, 1 = Failure)
- **Failure Type Prediction**: Multi-label classification for `HDA, OF, PF, RF, TWF, NF`

### 2ï¸âƒ£ Models Used

- **Tree-based models** ğŸŒ³: Random Forest, XGBoost
- **Neural Networks** ğŸ§ : Feedforward fully connected networks

### 3ï¸âƒ£ Evaluation Metrics

- Accuracy âœ…
- F1-score ğŸ¯
- Confusion matrix ğŸ”³

### 4ï¸âƒ£ Data Split

- Training: 80% ğŸ‹ï¸â€â™‚ï¸
- Validation: 10% ğŸ”
- Test: 10% ğŸ§ª

---

## ğŸ“ˆ Key Insights

1. **Tool wear** and **rotational speed** are the most predictive features âš¡.
2. Rare failure types require oversampling to prevent model bias ğŸ‹ï¸â€â™‚ï¸.
3. **Balancing dataset** significantly improves prediction on minority classes ğŸ“Š.
4. One-hot encoding of failure types enhances Neural Network performance ğŸ§©.

---

## ğŸ› ï¸ Dependencies

- Python 3.10+
- Pandas ğŸ¼
- Numpy ğŸ”¢
- Matplotlib ğŸ“Š
- Seaborn ğŸ¨
- Scikit-learn ğŸ«
- Imbalanced-learn âš–ï¸

Install all dependencies:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn imbalanced-learn
```
